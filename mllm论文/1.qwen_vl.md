# qwen vl

论文链接：[Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond (arxiv.org)](https://arxiv.org/abs/2308.12966 "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond (arxiv.org)")

## 0.摘要

- Qwen-VL系列模型在多种视觉中心任务上设立了新的记录，包括图像描述、问答、视觉定位等。
- 该模型支持多语言对话、多图像输入、文本阅读和定位等功能。

## 1.引言

- 大型语言模型（LLMs）在文本生成和理解方面的强大能力，但缺乏处理图像、语音和视频等其他常见模态的能力。
- 为了解决这个问题，研究者开发了大型视觉-语言模型（LVLMs），以增强LLMs的感知和理解视觉信号的能力。

## 2.模型架构

Qwen-VL模型的整体神经网络结构由三个主要组件构成：**大型语言模型（Large Language Model, LLM）**、**视觉编码器（Visual Encoder）**和**位置感知视觉-语言适配器（Position-aware Vision-Language Adapter）**。

### 2.1 大型语言模型 (LLM)

- Qwen-VL采用一个大型预训练的语言模型作为其基础组件。
- 该模型使用Qwen-7B语言模型的预训练权重进行初始化。

### 2.2 视觉编码器 (Visual Encoder)

- Qwen-VL的视觉编码器使用Vision Transformer (ViT)架构。
- 视觉编码器使用OpenCLIP的ViT-bigG的预训练权重进行初始化。
- 在训练和推理过程中，**输入图像被调整到特定的分辨率，然后被分割成小块（patches）**，生成一组图像特征。

### 2.3 位置感知视觉-语言适配器 (Position-aware Vision-Language Adapter)

- 为了解决长图像特征序列带来的效率问题，Qwen-VL引入了一个视觉-语言适配器，该适配器通过交叉注意机制压缩图像特征。
- 该适配器由单个交叉注意模块组成，该模块使用一组可训练的向量（嵌入）作为查询向量，使用视觉编码器生成的图像特征作为键（key）进行交叉注意操作。
- 通过这种机制，将视觉特征序列压缩成长度为256的固定长度。压缩后的特征序列随后输入到大型语言模型中。

### 2.4 输入输出接口

- 图像输入：图像通过视觉编码器和适配器处理，生成固定长度的图像特征序列。
- 文本输入：与图像特征序列区分开来，通常使用特殊的标记（如 `<img>` 和 `</img>`）来标识图像内容的开始和结束。

### 2.5模型参数

- 视觉编码器（ViT）：约1.9B个参数。
- 视觉-语言适配器（VL Adapter）：约0.08B个参数。
- 大型语言模型（LLM）：约7.7B个参数。
- 总计：约9.6B个参数。

## 3.训练细节

Qwen-VL模型的训练过程包括三个主要阶段：**两个预训练阶段**和**指令微调（Supervised Fine-tuning）阶段**。

![](image/image_OkUkvkxhfu.png)

### 3.1 预训练（第一阶段）

- **数据集**：使用大规模、弱标注的网络爬虫图像-文本对，包括多个公开可访问的来源和一些内部数据。
- **数据清洗**：原始数据集包含50亿图像-文本对，清洗后剩余14亿数据，其中77.3%为英文数据，22.7%为中文数据。
- **模型组件**：在此阶段，**大语言模型（LLM）参数被冻结，只优化视觉编码器（ViT）和视觉-语言适配器（VL Adapter）**。
- **输入图像尺寸**：输入图像被调整至224×224分辨率。
- **训练目标**：最小化文本令牌的交叉熵。
- **学习率**：最大学习率为2e-4。
- **训练步骤**：整个预训练阶段持续50,000步，使用30720的批次大小处理大约15亿图像-文本样本。

### 3.2 多任务预训练（第二阶段）

- **数据集**：引入高质量、细粒度的视觉语言注释数据，并使用更高的输入分辨率和交错的图像-文本数据。
- **任务**：同时训练Qwen-VL模型在7个任务上，包括图像字幕、视觉问答（VQA）、文本生成、文本定向的视觉问答、视觉定位、基于参考的定位和基于参考的字幕。
- **输入图像尺寸**：视觉编码器的输入分辨率从224×224增加到448×448，以减少图像下采样造成的信息损失。
- **模型组件**：**解锁大语言模型，训练整个模型。**
- **训练目标**：与预训练阶段相同。

### 3.3 指令微调（第三阶段）

- **目的**：通过指令微调来增强Qwen-VL预训练模型的指令跟随和对话能力，产生交互式的Qwen-VL-Chat模型。
- **数据**：多模态指令调整数据主要来自通过LLM自指令生成的字幕数据或对话数据，以及通过手动注释、模型生成和策略串联构建的额外对话数据集。
- **模型组件**：在这个阶段，**冻结视觉编码器，优化语言模型和适配器模块**。
- **数据量**：指令调整数据量达到350k。
- **训练目标**：确保模型在对话能力上的通用性，通过在训练中混合多模态和纯文本对话数据。

### 3.4 训练细节

- **优化器**：在所有训练阶段中，使用AdamW优化器，具有特定的β1、β2和ε参数。
- **学习率调度**：采用余弦衰减学习率计划。
- **权重衰减**：设置为0.05。
- **梯度裁剪**：应用1.0的梯度裁剪。
- **批次大小和梯度累积**：根据训练阶段调整批次大小和梯度累积。
- **数值精度**：使用bfloat16数值精度。
- **模型并行性**：在第二阶段使用模型并行性技术。

### 3.5 关于预训练阶段的交叉熵loss详解

大语言模型训练的核心机制 - **Teacher Forcing** 和 **交叉熵损失的逐token计算**。让我详细解释:

---

#### 预训练阶段Loss计算详解

##### 一、关键概念:Teacher Forcing

###### 1.1 什么是Teacher Forcing?

**训练时**的关键机制:
- 模型**每一步的输入使用真实标签(ground truth)**,而非自己的预测
- 即使模型预测错误,下一步仍然喂入正确的token
- 这样可以加速训练收敛,避免错误累积

让我举个例子说明: 可能在一般人理解中，大模型的gt和预测值可能是下面这样的：

```
Ground Truth: "This is a dog."
模型实际预测: "I can see this cat." 

但这是不可能的，在生成式ai的训练过程中,模型看到的输入序列始终是ground truth! (这个往往是初学者迷惑的根源)
```

---

##### 二、具体Loss计算流程

###### 2.1 完整示例设置

假设:
```python
# 输入图像
Image: [一张狗的照片]

# Ground Truth Caption
GT: "This is a dog."

# 词汇表 (简化示例)
vocab = {
    "<img>": 0, "</img>": 1, "This": 2, "is": 3, "a": 4, 
    "dog": 5, "cat": 6, ".": 7, "<eos>": 8,
    "I": 9, "can": 10, "see": 11, "this": 12
}

# Tokenized Ground Truth
tokens = [0, ...(256个图像tokens), 1, 2, 3, 4, 5, 7, 8]
#        <img>  [image features]   </img> This is a dog . <eos>
```

###### 2.2 模型前向传播

```python
# Step 1: 输入序列构造
input_sequence = [0, ...256 image tokens..., 1, 2, 3, 4, 5, 7]
#                <img>  [image features]  </img> This is a dog .

# Step 2: 模型输出logits (未归一化的分数)
# 形状: [seq_len, vocab_size]
# 这里是核心，通过将整个输入序列送入大模型，通过调用model的forward方法，能够并行输出整个序列中每一个token位置的概率，他的原理
# 可以这么简单理解，就是我先将input_sequence的第一个词送入到大模型中，让大模型输出下一个词的概率就是[1, vocab_size], 之后我再将
# input_sequence的前两个词送入到大模型中，让大模型输出下一个词的概率就是[1, vocab_size]，....， 如此循环，就可以实现大模型对
# input_sequence序列中每一个词的预测概率，并且每一次输出都是input_sequence中的部分真实序列。在实际过程中，这些循环其实是可以并行
# 计算的，因为整个input_sequence是已知的，可以通过mask操作+并行计算直接计算出整个序列的概率，也就是这里的[seq_len, vocab_size].
logits = model(input_sequence)  # [259, 13]  (259 = 1+256+1+5+1)

# Step 3: 对logits做softmax得到概率分布
probs = softmax(logits, dim=-1)  # [259, 13]
```

###### 2.3 每个位置的预测概率分布

让我详细展示**每个文本位置**的概率分布:

```
位置 258 (在"This"之后,预测"is"):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
输入: <img>[256 toks]</img>This
预测目标: "is" (token_id = 3)

模型输出概率分布 (softmax后):
┌─────────┬─────────────┐
│ Token   │ Probability │
├─────────┼─────────────┤
│ <img>   │ 0.001       │
│ </img>  │ 0.002       │
│ This    │ 0.05        │
│ is      │ 0.65 ✓      │ ← Ground Truth
│ a       │ 0.10        │
│ dog     │ 0.08        │
│ cat     │ 0.03        │
│ .       │ 0.02        │
│ <eos>   │ 0.01        │
│ I       │ 0.02        │
│ can     │ 0.01        │
│ see     │ 0.01        │
│ this    │ 0.01        │
└─────────┴─────────────┘

Cross-Entropy Loss (此位置):
loss_258 = -log(P(is)) = -log(0.65) = 0.43
```

```
位置 259 (在"is"之后,预测"a"):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
输入: <img>[256 toks]</img>This is
预测目标: "a" (token_id = 4)

模型输出概率分布:
┌─────────┬─────────────┐
│ Token   │ Probability │
├─────────┼─────────────┤
│ <img>   │ 0.001       │
│ </img>  │ 0.001       │
│ This    │ 0.02        │
│ is      │ 0.03        │
│ a       │ 0.70 ✓      │ ← Ground Truth
│ dog     │ 0.15        │
│ cat     │ 0.04        │
│ .       │ 0.02        │
│ <eos>   │ 0.01        │
│ I       │ 0.01        │
│ can     │ 0.005       │
│ see     │ 0.005       │
│ this    │ 0.01        │
└─────────┴─────────────┘

Cross-Entropy Loss:
loss_259 = -log(0.70) = 0.36
```

```
位置 260 (在"a"之后,预测"dog"):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
输入: <img>[256 toks]</img>This is a
预测目标: "dog" (token_id = 5)

假设模型这里预测错了,给"cat"更高概率:
┌─────────┬─────────────┐
│ Token   │ Probability │
├─────────┼─────────────┤
│ <img>   │ 0.001       │
│ </img>  │ 0.001       │
│ This    │ 0.01        │
│ is      │ 0.02        │
│ a       │ 0.05        │
│ dog     │ 0.25 ✓      │ ← Ground Truth (但概率不是最高!)
│ cat     │ 0.60 ✗      │ ← 模型错误预测这个
│ .       │ 0.03        │
│ <eos>   │ 0.01        │
│ I       │ 0.01        │
│ can     │ 0.005       │
│ see     │ 0.005       │
│ this    │ 0.01        │
└─────────┴─────────────┘

Cross-Entropy Loss:
loss_260 = -log(P(dog))  ← 注意:只看ground truth的概率!
         = -log(0.25) 
         = 1.39  ← 比前面的loss大很多!
```

###### 2.4 总Loss计算

```python
# 只对文本token位置计算loss (忽略图像token)
total_loss = (loss_258 + loss_259 + loss_260 + loss_261 + loss_262) / 5

假设各位置loss:
position 258 ("is"):   -log(0.65) = 0.43
position 259 ("a"):    -log(0.70) = 0.36
position 260 ("dog"):  -log(0.25) = 1.39  ← 预测错误,loss很大
position 261 ("."):    -log(0.80) = 0.22
position 262 ("<eos>"): -log(0.75) = 0.29

total_loss = (0.43 + 0.36 + 1.39 + 0.22 + 0.29) / 5
           = 2.69 / 5
           = 0.54
```

---

##### 三、关键机制详解

###### 3.1 Teacher Forcing的完整流程

```
训练时的序列处理:

Time Step    Input Tokens                    Target    Model Prediction    Loss
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
t=258        <img>[256]</img>This           is        P(is)=0.65          -log(0.65)
             └─ 用GT "This" ─┘                        P(cat)=0.03

t=259        <img>[256]</img>This is        a         P(a)=0.70           -log(0.70)
             └─ 用GT "is" ─┘                          P(dog)=0.15

t=260        <img>[256]</img>This is a      dog       P(dog)=0.25         -log(0.25) ← 高loss
             └─ 用GT "a" ─┘                           P(cat)=0.60 ← 虽然这个最高,但不用!

t=261        <img>[256]</img>This is a dog  .         P(.)=0.80           -log(0.80)
             └─ 用GT "dog" (不是模型预测的"cat")! ─┘
```

**重点**:
- 即使t=260时模型预测"cat"概率最高(0.60)
- t=261的输入仍然使用GT中的"dog"
- **这就是Teacher Forcing**: 始终用真实标签作为下一步输入

###### 3.2 为什么这样设计?

**优势**:
1. **加速收敛**: 不会因为早期错误预测导致后续全部错误
2. **稳定训练**: 每个位置的loss都有明确的监督信号
3. **并行计算**: 可以一次性计算所有位置的loss

**劣势**(推理时的exposure bias 暴露偏见):
- 训练时见的是GT,推理时见的是自己的预测
- 因此需要inference时的自回归生成策略

---

##### 四、完整代码实现

让我用实际代码展示:

```python
import torch
import torch.nn.functional as F

def compute_language_modeling_loss(logits, labels, ignore_index=-100):
    """
    参数:
        logits: [batch_size, seq_len, vocab_size] 模型输出的未归一化分数
        labels: [batch_size, seq_len] ground truth token IDs
        ignore_index: 需要忽略的token ID (如图像token位置)
    
    返回:
        loss: 标量
    """
    # Step 1: Shift操作 (预测下一个token)
    # 输入: <img>[256]</img>This is a dog .
    # 预测: [256]</img>This is a dog . <eos>
    shift_logits = logits[:, :-1, :].contiguous()  # [B, seq_len-1, vocab]
    shift_labels = labels[:, 1:].contiguous()      # [B, seq_len-1]
    
    # Step 2: Flatten
    shift_logits = shift_logits.view(-1, shift_logits.size(-1))  # [B*(seq_len-1), vocab]
    shift_labels = shift_labels.view(-1)                          # [B*(seq_len-1)]
    
    # Step 3: 计算Cross-Entropy
    # reduction='mean': 自动对所有非ignore位置求平均
    loss = F.cross_entropy(
        shift_logits,
        shift_labels,
        ignore_index=ignore_index,
        reduction='mean'
    )
    
    return loss


# 具体例子
batch_size = 1
seq_len = 264  # 1 + 256 + 1 + 6 (包括<img>, image tokens, </img>, 文本)
vocab_size = 151851

# 模拟模型输出
logits = torch.randn(batch_size, seq_len, vocab_size)  # 随机初始化

# Ground Truth labels
labels = torch.tensor([[
    0,     # <img>
    *[100]*256,  # 256个图像token IDs
    1,     # </img>
    2,     # This
    3,     # is
    4,     # a
    5,     # dog
    7,     # .
    8      # <eos>
]])

# 标记图像token位置为ignore
labels[:, 1:258] = -100  # 图像token不计算loss

# 计算loss
loss = compute_language_modeling_loss(logits, labels)
print(f"Total Loss: {loss.item()}")
```

###### 4.1 逐token loss计算示例

```python
def detailed_loss_computation(logits, labels):
    """
    展示每个位置的loss计算细节
    """
    seq_len = logits.size(1)
    vocab_size = logits.size(2)
    
    print("Position-wise Loss Breakdown:")
    print("=" * 80)
    
    total_loss = 0
    num_tokens = 0
    
    for pos in range(seq_len - 1):
        # 当前位置的logits
        current_logits = logits[0, pos, :]  # [vocab_size]
        
        # 下一个位置的ground truth
        target_token_id = labels[0, pos + 1].item()
        
        # 跳过ignore token
        if target_token_id == -100:
            continue
        
        # 计算概率分布
        probs = F.softmax(current_logits, dim=0)
        
        # 目标token的概率
        target_prob = probs[target_token_id].item()
        
        # 预测最可能的token
        pred_token_id = torch.argmax(probs).item()
        
        # 该位置的loss
        token_loss = -torch.log(probs[target_token_id])
        
        print(f"Position {pos:3d}:")
        print(f"  Input: tokens[0:{pos+1}]")
        print(f"  Target: token_id={target_token_id}")
        print(f"  P(target)={target_prob:.4f}")
        print(f"  Predicted: token_id={pred_token_id}")
        print(f"  Loss: -log({target_prob:.4f}) = {token_loss.item():.4f}")
        
        if pred_token_id != target_token_id:
            print(f"  ⚠️  WRONG PREDICTION! (GT: {target_token_id}, Pred: {pred_token_id})")
        
        print()
        
        total_loss += token_loss.item()
        num_tokens += 1
    
    avg_loss = total_loss / num_tokens
    print(f"Average Loss: {avg_loss:.4f}")
    return avg_loss
```

---

##### 五、你的例子详细分析

###### 5.1 场景设定

```
Ground Truth: "This is a dog."
模型预测(假设): "I can see this cat."
```

###### 5.2 实际Loss计算过程

```python
序列位置分解:
┌─────┬──────────────┬────────┬──────────────┬─────────┬──────────┐
│ Pos │ Input Seq    │ Target │ GT Token     │ Prob    │ Loss     │
├─────┼──────────────┼────────┼──────────────┼─────────┼──────────┤
│ 257 │ <img>[..]</img>     │ This   │ This         │ 0.01    │ 4.61 ✗   │
│     │              │        │ (模型可能输出"I") │         │          │
├─────┼──────────────┼────────┼──────────────┼─────────┼──────────┤
│ 258 │ <img>[..]</img>This │ is     │ is           │ 0.02    │ 3.91 ✗   │
│     │              │        │ (模型可能输出"can")│        │          │
├─────┼──────────────┼────────┼──────────────┼─────────┼──────────┤
│ 259 │ ...This is   │ a      │ a            │ 0.03    │ 3.51 ✗   │
│     │              │        │ (模型可能输出"see")│        │          │
├─────┼──────────────┼────────┼──────────────┼─────────┼──────────┤
│ 260 │ ...This is a │ dog    │ dog          │ 0.05    │ 3.00 ✗   │
│     │              │        │ (模型可能输出"this")│       │          │
├─────┼──────────────┼────────┼──────────────┼─────────┼──────────┤
│ 261 │ ...is a dog  │ .      │ .            │ 0.10    │ 2.30 ✗   │
│     │              │        │ (模型可能输出"cat")│        │          │
└─────┴──────────────┴────────┴──────────────┴─────────┴──────────┘

Total Loss = (4.61 + 3.91 + 3.51 + 3.00 + 2.30) / 5 = 3.47
```

**关键点**:
1. **每个位置的输入都是GT序列的前缀**
2. **Loss只看GT token的概率**,不管模型实际预测什么
3. **预测错误 → GT token概率低 → Loss大**

###### 5.3 训练中的梯度更新

```python
# 伪代码
for batch in dataloader:
    images, captions = batch
    
    # 前向传播
    logits = model(images, captions[:, :-1])  # 输入: 除了最后一个token
    
    # 计算loss
    loss = cross_entropy(logits, captions[:, 1:])  # 目标: 除了第一个token
    
    # 反向传播
    loss.backward()
    
    # 参数更新
    optimizer.step()
    
    # Loss大 → 梯度大 → 参数调整幅度大
    # 目标: 下次预测时,P(dog) ↑, P(cat) ↓
```

---

##### 六、常见误解澄清

###### ❌ 误解1: "模型预测错了,就不计算loss?"
**✅ 正确**: 无论预测对错,都计算loss。预测错误时,GT token概率低,loss更大。

###### ❌ 误解2: "预测'cat'时,loss是根据'cat'计算的?"
**✅ 正确**: loss永远只看GT token("dog")的概率,与预测的"cat"无直接关系。

###### ❌ 误解3: "模型输出'I can see this cat'会直接用于下一步?"
**✅ 正确**: 训练时使用Teacher Forcing,下一步输入仍是GT。只有推理时才用模型自己的预测。

###### ❌ 误解4: "所有位置的loss权重相同?"
**✅ 正确**: 默认相同,但可以通过调整实现不同权重(如SFT阶段只监督assistant回答)。

---

##### 七、推理时的区别

###### 7.1 训练 vs 推理对比

```
【训练时 - Teacher Forcing】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Step 1: Input: <img>[..]</img>
        Output Probs: {"I": 0.6, "This": 0.01, ...}
        Next Input: <img>[..]</img>This  ← 用GT!

Step 2: Input: <img>[..]</img>This
        Output Probs: {"can": 0.5, "is": 0.02, ...}
        Next Input: <img>[..]</img>This is  ← 用GT!

...持续使用GT作为输入


【推理时 - Autoregressive Generation】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Step 1: Input: <img>[..]</img>
        Output Probs: {"I": 0.6, "This": 0.01, ...}
        Sample: "I"
        Next Input: <img>[..]</img>I  ← 用自己的预测!

Step 2: Input: <img>[..]</img>I
        Output Probs: {"can": 0.5, "think": 0.3, ...}
        Sample: "can"
        Next Input: <img>[..]</img>I can  ← 用自己的预测!

...持续使用模型自己的预测
```

###### 7.2 为什么训练和推理不一致?

这就是著名的 **Exposure Bias** 问题:
- 训练时总是看到"正确"的历史
- 推理时可能看到"错误"的历史
- 导致误差累积

**缓解方法**:
1. Scheduled Sampling: 训练时偶尔使用模型预测
2. 大规模预训练: 让模型更鲁棒
3. RLHF: 强化学习微调

---

##### 八、总结

###### Loss计算的本质

```python
# 对于每个位置 i:
loss_i = -log(P(ground_truth_token_i | history))

# 其中 history 在训练时是 ground_truth[:i]
# P(...) 是模型输出的softmax概率分布中,GT token对应的概率

# 总loss:
total_loss = mean(loss_i for all non-ignored positions)
```

**核心要点**:
1. ✅ Loss只关心GT token的概率,不管预测什么
2. ✅ 预测错误 = GT概率低 = Loss大 = 梯度大 = 更多学习
3. ✅ Teacher Forcing确保训练稳定,但带来exposure bias
4. ✅ 交叉熵自动实现"预测越错,惩罚越大"

希望这个详细的解释解答了你的疑问!

##### 4.数据格式

###### 4.1 多任务训练数据格式

下图包含所有 7 个任务，其中黑色文本作为不计算损失的前缀序列，蓝色文本作为有损失的真实标签。

![](image/image_sszW6nCzYk.png)

###### 4.2 微调数据格式

为了更好地适应多图像对话和多个图像输入，在不同图像之前添加字符串`Picture id:`，其中id对应于图像输入对话的顺序。在对话格式方面，使用 ChatML (Openai) 格式构建指令调整数据集，其中每个交互的语句都标有两个特殊标记（`<im_start>` 和 `<im_end>`），以方便对话终止。

![](image/image_o5Q33jgUeD.png)

在训练过程中，通过仅监督答案和特殊标记（示例中的蓝色）而不监督角色名称或问题提示来确保预测和训练分布之间的一致性。
